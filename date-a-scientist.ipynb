{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OKCupid Machine Learning Project**\n",
    "## **================================**\n",
    "This project analyzes data from on-line dating application OKCupid. In recent years, there has been a massive rise in the usage of dating apps to find love. Many of these apps use sophisticated data science techniques to recommend possible matches to users and to optimize the user experience. These apps give us access to a wealth of information that we've never had before about how different people experience romance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Project Objetives**\n",
    "The goals of this project is to **scope, prepare and analyze the data**. The second goal is to **create ML model(s)** that can solve questions and predict outcomes. Depending on the results and resources available, the model could be tuned and optimised. \n",
    "- Load and check the data\n",
    "- Exploratory data analysis\n",
    "- Select the ML model\n",
    "- Prepare the data  \n",
    "- Build the model(s)\n",
    "- Train and evaluate the model(s)\n",
    "- Conclusions \n",
    "### **Dataset**\n",
    "\n",
    "The dataset used in this project is from [Kaggle](https://www.kaggle.com/datasets/andrewmvd/okcupid-profiles). The dataset contains information about 60,000 users and their responses to a set of questions. OkCupid is a mobile dating app. It sets itself apart from other dating apps by making use of a pre computed compatibility score, calculated by optional questions the users may choose to answer. In this dataset, there are 60k records containing structured information such as age, sex, orientation as well as text data from open ended descriptions in 30 columns.\n",
    "\n",
    "##### The columns in the dataset include: \n",
    "- ``age:`` continuous variable of age of user\n",
    "- ``body_type:`` categorical variable of body type of user\n",
    "- ``diet:`` categorical variable of dietary information\n",
    "- ``drinks:``  categorical variable of alcohol consumption\n",
    "- ``drugs:`` categorical variable of drug usage\n",
    "- ``education:`` categorical variable of educational attainment\n",
    "- ``ethnicity:`` categorical variable of ethnic backgrounds\n",
    "- ``height:`` continuous variable of height of user\n",
    "- ``income:`` continuous variable of income of user\n",
    "- ``job:`` categorical variable of employment description\n",
    "- ``offspring:`` categorical variable of children status\n",
    "- ``orientation:`` categorical variable of sexual orientation\n",
    "- ``pets:`` categorical variable of pet preferences\n",
    "- ``religion:`` categorical variable of religious background\n",
    "- ``sex:`` categorical variable of gender\n",
    "- ``sign:`` categorical variable of astrological symbol\n",
    "- ``smokes:`` categorical variable of smoking consumption\n",
    "- ``speaks:`` categorical variable of language spoken\n",
    "- ``status:`` categorical variable of relationship status\n",
    "- ``last_online:`` date variable of last login\n",
    "##### And a set of open short-answer responses to :\n",
    "- ``essay0:`` My self summary\n",
    "- ``essay1:``  What I’m doing with my life\n",
    "- ``essay2:`` I’m really good at\n",
    "- ``essay3:`` The first thing people usually notice about me\n",
    "- ``essay4:`` Favorite books, movies, show, music, and food\n",
    "- ``essay5:`` The six things I could never do without\n",
    "- ``essay6:`` I spend a lot of time thinking about\n",
    "- ``essay7:`` On a typical Friday night I am\n",
    "- ``essay8:`` The most private thing I am willing to admit\n",
    "- ``essay9:`` You should message me if…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Load and check the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "#set theme for the seaborn plots\n",
    "#context is for the size of the plot\n",
    "#style is for the background of the plot\n",
    "#palette is for the color of the plot\n",
    "#font is for the font of the plot\n",
    "#font_scale is for the size of the font\n",
    "#color_codes is for the color of the plot\n",
    "sn.set_theme(context='notebook', style='darkgrid', palette='tab10', font='sans-serif', font_scale=1, color_codes=True, rc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   body_type    54650 non-null  object \n",
      " 2   diet         35551 non-null  object \n",
      " 3   drinks       56961 non-null  object \n",
      " 4   drugs        45866 non-null  object \n",
      " 5   education    53318 non-null  object \n",
      " 6   essay0       54458 non-null  object \n",
      " 7   essay1       52374 non-null  object \n",
      " 8   essay2       50308 non-null  object \n",
      " 9   essay3       48470 non-null  object \n",
      " 10  essay4       49409 non-null  object \n",
      " 11  essay5       49096 non-null  object \n",
      " 12  essay6       46175 non-null  object \n",
      " 13  essay7       47495 non-null  object \n",
      " 14  essay8       40721 non-null  object \n",
      " 15  essay9       47343 non-null  object \n",
      " 16  ethnicity    54266 non-null  object \n",
      " 17  height       59943 non-null  float64\n",
      " 18  income       59946 non-null  int64  \n",
      " 19  job          51748 non-null  object \n",
      " 20  last_online  59946 non-null  object \n",
      " 21  location     59946 non-null  object \n",
      " 22  offspring    24385 non-null  object \n",
      " 23  orientation  59946 non-null  object \n",
      " 24  pets         40025 non-null  object \n",
      " 25  religion     39720 non-null  object \n",
      " 26  sex          59946 non-null  object \n",
      " 27  sign         48890 non-null  object \n",
      " 28  smokes       54434 non-null  object \n",
      " 29  speaks       59896 non-null  object \n",
      " 30  status       59946 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59946.000000</td>\n",
       "      <td>54650</td>\n",
       "      <td>35551</td>\n",
       "      <td>56961</td>\n",
       "      <td>45866</td>\n",
       "      <td>53318</td>\n",
       "      <td>54458</td>\n",
       "      <td>52374</td>\n",
       "      <td>50308</td>\n",
       "      <td>48470</td>\n",
       "      <td>...</td>\n",
       "      <td>59946</td>\n",
       "      <td>24385</td>\n",
       "      <td>59946</td>\n",
       "      <td>40025</td>\n",
       "      <td>39720</td>\n",
       "      <td>59946</td>\n",
       "      <td>48890</td>\n",
       "      <td>54434</td>\n",
       "      <td>59896</td>\n",
       "      <td>59946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>54350</td>\n",
       "      <td>51516</td>\n",
       "      <td>48635</td>\n",
       "      <td>43533</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>7647</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>.</td>\n",
       "      <td>enjoying it.</td>\n",
       "      <td>listening</td>\n",
       "      <td>my smile</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14652</td>\n",
       "      <td>16585</td>\n",
       "      <td>41780</td>\n",
       "      <td>37724</td>\n",
       "      <td>23959</td>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "      <td>82</td>\n",
       "      <td>529</td>\n",
       "      <td>...</td>\n",
       "      <td>31064</td>\n",
       "      <td>7560</td>\n",
       "      <td>51606</td>\n",
       "      <td>14814</td>\n",
       "      <td>2724</td>\n",
       "      <td>35829</td>\n",
       "      <td>1782</td>\n",
       "      <td>43896</td>\n",
       "      <td>21828</td>\n",
       "      <td>55697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.340290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.452779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age body_type             diet    drinks  drugs  \\\n",
       "count   59946.000000     54650            35551     56961  45866   \n",
       "unique           NaN        12               18         6      3   \n",
       "top              NaN   average  mostly anything  socially  never   \n",
       "freq             NaN     14652            16585     41780  37724   \n",
       "mean       32.340290       NaN              NaN       NaN    NaN   \n",
       "std         9.452779       NaN              NaN       NaN    NaN   \n",
       "min        18.000000       NaN              NaN       NaN    NaN   \n",
       "25%        26.000000       NaN              NaN       NaN    NaN   \n",
       "50%        30.000000       NaN              NaN       NaN    NaN   \n",
       "75%        37.000000       NaN              NaN       NaN    NaN   \n",
       "max       110.000000       NaN              NaN       NaN    NaN   \n",
       "\n",
       "                                education essay0        essay1     essay2  \\\n",
       "count                               53318  54458         52374      50308   \n",
       "unique                                 32  54350         51516      48635   \n",
       "top     graduated from college/university      .  enjoying it.  listening   \n",
       "freq                                23959     12            61         82   \n",
       "mean                                  NaN    NaN           NaN        NaN   \n",
       "std                                   NaN    NaN           NaN        NaN   \n",
       "min                                   NaN    NaN           NaN        NaN   \n",
       "25%                                   NaN    NaN           NaN        NaN   \n",
       "50%                                   NaN    NaN           NaN        NaN   \n",
       "75%                                   NaN    NaN           NaN        NaN   \n",
       "max                                   NaN    NaN           NaN        NaN   \n",
       "\n",
       "          essay3  ...                   location                offspring  \\\n",
       "count      48470  ...                      59946                    24385   \n",
       "unique     43533  ...                        199                       15   \n",
       "top     my smile  ...  san francisco, california  doesn&rsquo;t have kids   \n",
       "freq         529  ...                      31064                     7560   \n",
       "mean         NaN  ...                        NaN                      NaN   \n",
       "std          NaN  ...                        NaN                      NaN   \n",
       "min          NaN  ...                        NaN                      NaN   \n",
       "25%          NaN  ...                        NaN                      NaN   \n",
       "50%          NaN  ...                        NaN                      NaN   \n",
       "75%          NaN  ...                        NaN                      NaN   \n",
       "max          NaN  ...                        NaN                      NaN   \n",
       "\n",
       "       orientation                       pets     religion    sex  \\\n",
       "count        59946                      40025        39720  59946   \n",
       "unique           3                         15           45      2   \n",
       "top       straight  likes dogs and likes cats  agnosticism      m   \n",
       "freq         51606                      14814         2724  35829   \n",
       "mean           NaN                        NaN          NaN    NaN   \n",
       "std            NaN                        NaN          NaN    NaN   \n",
       "min            NaN                        NaN          NaN    NaN   \n",
       "25%            NaN                        NaN          NaN    NaN   \n",
       "50%            NaN                        NaN          NaN    NaN   \n",
       "75%            NaN                        NaN          NaN    NaN   \n",
       "max            NaN                        NaN          NaN    NaN   \n",
       "\n",
       "                                            sign  smokes   speaks  status  \n",
       "count                                      48890   54434    59896   59946  \n",
       "unique                                        48       5     7647       5  \n",
       "top     gemini and it&rsquo;s fun to think about      no  english  single  \n",
       "freq                                        1782   43896    21828   55697  \n",
       "mean                                         NaN     NaN      NaN     NaN  \n",
       "std                                          NaN     NaN      NaN     NaN  \n",
       "min                                          NaN     NaN      NaN     NaN  \n",
       "25%                                          NaN     NaN      NaN     NaN  \n",
       "50%                                          NaN     NaN      NaN     NaN  \n",
       "75%                                          NaN     NaN      NaN     NaN  \n",
       "max                                          NaN     NaN      NaN     NaN  \n",
       "\n",
       "[11 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load the data\n",
    "profiles_data = pd.read_csv('profiles.csv')\n",
    "profiles_df = pd.DataFrame(profiles_data)\n",
    "\n",
    "display(profiles_df.info())\n",
    "display(profiles_df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>...</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>...</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at:&lt;br /&gt;\\nhttp://bag...</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks      drugs  \\\n",
       "0   22  a little extra  strictly anything  socially      never   \n",
       "1   35         average       mostly other     often  sometimes   \n",
       "2   38            thin           anything  socially        NaN   \n",
       "3   23            thin         vegetarian  socially        NaN   \n",
       "4   29        athletic                NaN  socially      never   \n",
       "\n",
       "                           education  \\\n",
       "0      working on college/university   \n",
       "1              working on space camp   \n",
       "2     graduated from masters program   \n",
       "3      working on college/university   \n",
       "4  graduated from college/university   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:<br />\\n<br />\\ni would love to think...   \n",
       "1  i am a chef: this is what that means.<br />\\n1...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\nranting about a go...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at:<br />\\nhttp://bag...   \n",
       "\n",
       "                                              essay3  ...  \\\n",
       "0  the way i look. i am a six foot half asian, ha...  ...   \n",
       "1                                                NaN  ...   \n",
       "2  my large jaw and large glasses are the physica...  ...   \n",
       "3                  socially awkward but i do my best  ...   \n",
       "4            i smile a lot and my inquisitive nature  ...   \n",
       "\n",
       "                          location  \\\n",
       "0  south san francisco, california   \n",
       "1              oakland, california   \n",
       "2        san francisco, california   \n",
       "3             berkeley, california   \n",
       "4        san francisco, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                           NaN    straight   \n",
       "3                       doesn&rsquo;t want kids    straight   \n",
       "4                                           NaN    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "3                 likes cats                                       NaN   m   \n",
       "4  likes dogs and likes cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks     status  \n",
       "0                                            english     single  \n",
       "1  english (fluently), spanish (poorly), french (...     single  \n",
       "2                               english, french, c++  available  \n",
       "3                           english, german (poorly)     single  \n",
       "4                                            english     single  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(profiles_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Select the ML model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Prepare the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Build the model(s)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Train and Evaluate the model(s)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Conclusions**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
